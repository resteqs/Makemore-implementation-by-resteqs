{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises Part2: \n",
    "- E01: Tune the hyperparameters of the training to beat my best validation loss of 2.2\n",
    "- E02: I was not careful with the intialization of the network in this video. (1) What is the loss you'd get if the predicted probabilities at initialization were perfectly uniform? What loss do we achieve? (2) Can you tune the initialization to get a starting loss that is much more similar to (1)?\n",
    "- E03: Read the Bengio et al 2003 paper ([link](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbnlHNlB5V2ZGT3lSVVljeXNMMGlUa2ktbmx3d3xBQ3Jtc0tsUGdMSU5OcWVEUHFxd0RzTVJQLVZnMzY3N3UzQXlzRE93ZjEydklDR0YwYWd6OThLNDJvNFNFM3FkajhGWGNtaU9ZVXl2VmkzR0NoYWdNUGpyeTd1RG9LN1dSRklQUHdkaEs5RWlPQWZxeW1rLUM3QQ&q=https%3A%2F%2Fwww.jmlr.org%2Fpapers%2Fvolume3%2Fbengio03a%2Fbengio03a.pdf&v=TCH_1BHY58I)), implement and try any idea from the paper. Did it work?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt #for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "#String to integer and integer to string mappings have been created\n",
    "chars = sorted(list(set( \"\".join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 #Number of characters used to predict the next one \n",
    "X, Y = [], [] #X are the inputs, Y are the labels\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + \".\":\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(\"\".join(itos[i] for i in context), \"--->\", itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"Screenshot 2024-05-14 150859.png\" width= \"600\n",
    "\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5580, -0.5386],\n",
       "        [-0.1774,  0.3138],\n",
       "        [ 1.1124, -0.0921],\n",
       "        [ 1.1124, -0.0921],\n",
       "        [ 1.1124, -0.0921],\n",
       "        [ 1.1124, -0.0921]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn((27, 2)) #We want to embed each of our 27 characters into a 2 dimensionial space\n",
    "C\n",
    "C[5]\n",
    "C[[5,6,7]]\n",
    "C[torch.tensor([5,6,7,7,7,7])] #Some random ways to access only some specific rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875],\n",
       "         [ 1.5580, -0.5386]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [ 1.5580, -0.5386],\n",
       "         [-1.3439,  0.5324]],\n",
       "\n",
       "        [[ 1.5580, -0.5386],\n",
       "         [-1.3439,  0.5324],\n",
       "         [-1.3439,  0.5324]],\n",
       "\n",
       "        [[-1.3439,  0.5324],\n",
       "         [-1.3439,  0.5324],\n",
       "         [-0.0338,  1.7611]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875],\n",
       "         [ 1.4627, -0.3431]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [ 1.4627, -0.3431],\n",
       "         [-1.1225,  1.1957]],\n",
       "\n",
       "        [[ 1.4627, -0.3431],\n",
       "         [-1.1225,  1.1957],\n",
       "         [ 0.1063,  2.2454]],\n",
       "\n",
       "        [[-1.1225,  1.1957],\n",
       "         [ 0.1063,  2.2454],\n",
       "         [-0.7675, -0.3616]],\n",
       "\n",
       "        [[ 0.1063,  2.2454],\n",
       "         [-0.7675, -0.3616],\n",
       "         [ 0.1063,  2.2454]],\n",
       "\n",
       "        [[-0.7675, -0.3616],\n",
       "         [ 0.1063,  2.2454],\n",
       "         [-0.0338,  1.7611]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875],\n",
       "         [-0.0338,  1.7611]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [-0.0338,  1.7611],\n",
       "         [-0.7675, -0.3616]],\n",
       "\n",
       "        [[-0.0338,  1.7611],\n",
       "         [-0.7675, -0.3616],\n",
       "         [-0.0338,  1.7611]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875],\n",
       "         [ 0.1063,  2.2454]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [ 0.1063,  2.2454],\n",
       "         [ 0.4664, -1.6295]],\n",
       "\n",
       "        [[ 0.1063,  2.2454],\n",
       "         [ 0.4664, -1.6295],\n",
       "         [-0.0338,  1.7611]],\n",
       "\n",
       "        [[ 0.4664, -1.6295],\n",
       "         [-0.0338,  1.7611],\n",
       "         [-0.1555, -1.2618]],\n",
       "\n",
       "        [[-0.0338,  1.7611],\n",
       "         [-0.1555, -1.2618],\n",
       "         [ 1.5580, -0.5386]],\n",
       "\n",
       "        [[-0.1555, -1.2618],\n",
       "         [ 1.5580, -0.5386],\n",
       "         [-1.1225,  1.1957]],\n",
       "\n",
       "        [[ 1.5580, -0.5386],\n",
       "         [-1.1225,  1.1957],\n",
       "         [-1.1225,  1.1957]],\n",
       "\n",
       "        [[-1.1225,  1.1957],\n",
       "         [-1.1225,  1.1957],\n",
       "         [-0.0338,  1.7611]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [-0.0592,  1.7875],\n",
       "         [ 0.4664, -1.6295]],\n",
       "\n",
       "        [[-0.0592,  1.7875],\n",
       "         [ 0.4664, -1.6295],\n",
       "         [ 1.4627, -0.3431]],\n",
       "\n",
       "        [[ 0.4664, -1.6295],\n",
       "         [ 1.4627, -0.3431],\n",
       "         [-1.3804, -0.0306]],\n",
       "\n",
       "        [[ 1.4627, -0.3431],\n",
       "         [-1.3804, -0.0306],\n",
       "         [-0.7986,  1.1125]],\n",
       "\n",
       "        [[-1.3804, -0.0306],\n",
       "         [-0.7986,  1.1125],\n",
       "         [ 0.1063,  2.2454]],\n",
       "\n",
       "        [[-0.7986,  1.1125],\n",
       "         [ 0.1063,  2.2454],\n",
       "         [-0.0338,  1.7611]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape\n",
    "emb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"Unbenannt.png\" width= \"600\n",
    "\"> </br>\n",
    "The indexes of letters from 0-26 get replaced by their embeding into a 2 Dimensional Space, with initial values generated at random from a normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9660,  0.9937, -0.9804,  ...,  0.9742, -0.0939,  0.9245],\n",
       "        [ 0.9887, -0.2929, -0.9995,  ...,  0.3528, -0.9914,  0.2964],\n",
       "        [-0.1756,  0.6162, -0.6402,  ...,  0.9999,  0.9884, -0.5720],\n",
       "        ...,\n",
       "        [ 0.6276,  0.5890,  0.9994,  ..., -0.9984,  0.8313,  0.9999],\n",
       "        [ 0.9900,  1.0000,  0.2879,  ..., -0.9772,  0.8287,  0.9995],\n",
       "        [ 0.9936,  0.9998, -0.9976,  ...,  0.9124, -0.1108,  0.8657]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = torch.randn((6,100)) #What does 6,100 mean? The Hidden layer in the middle has 3 inputs, which actually are our 3 characters as input\n",
    "# Each of them is embedded to 2D space 2x3 = 6. So each of the 100 Neurons we created is feeded with 6 values which all get a weight we first init randomly\n",
    "b1 = torch.randn(100) #Every neuron also gets a random bias \n",
    "\n",
    "#Neuron = (input1 * weight1 + ... + input6 * weight 6) + bias\n",
    "#So we want emb @ W1 + b1 which multiplies all our examples with weights and adds a bias BUT:\n",
    "#We can not multiply a shape [32,3,2] @ [100,6] we need to squash it to [32,6] @ [6,100]\n",
    "\n",
    "torch.cat(torch.unbind(emb, 1), 1)# <=> torch.cat ([emb[:,0 , :], emb[:,1 , :], emb[:,2 , :]], 1) Which means we take a list of 0th letters, 1st letters and 2nd letters and squash them\n",
    "\n",
    "#BUUUUUT! This is not very efficient... There is a better way\n",
    "\n",
    "#Each tensor stores something called .storage(), this is a one dimensional representation of the tensor, because thats how it is stored in PC memory\n",
    "#The method .view() manipulates how this originally one-dim tensor (or array in simpler words) is interpreted by PyTorch, so no values are copied, no additional memory is needed etc.\n",
    "\n",
    "h = emb.view(32,6) @ W1 + b1 #Voilaaaaaa!!!\n",
    "\n",
    "#BUUUT: We dont want to hardcode numbers...\n",
    "h = emb.view(emb.shape[0], 6) @ W1 + b1\n",
    "#But why is 6 still here... Shuu Shuu go away... Well we already agreed on 3 input letters and 2 Dimensional embedings so its kinda okay...\n",
    "\n",
    "h = torch.tanh(h) #Look at the image, the layer is non linear, it is a tanh \n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"Screenshot 2024-05-14 150859.png\" width= \"300\n",
    "\"><img src= \"tanh.jpg\" width= \"300\n",
    "\">\n",
    "<img src= \"hyperbolic functions.png\" width= \"300\n",
    "\">\n",
    "https://www.youtube.com/watch?v=HnHnEnkZpJA Video zum Thema hyperbolic trigonmometric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we create our Output layer:\n",
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)\n",
    "#Again lets take a moment here. We create a layer with 27 Neurons where each neuron gets 100 inputs from the 100 neurons of the previous layer\n",
    "logits = h @ W2 + b2 #What are logits? Logits are the outputs of a neural network. Usually, we plug the outputs to a softmax in order to receive a probability distribution \n",
    "counts = logits.exp()\n",
    "prob =  counts / counts.sum(1, keepdim= True) #Look at the image below. This is softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"th-1496899846.png\" alt=\"Example Image\" width=\"300\" >\n",
    "</br>\n",
    "We take our \"counts\" and transform them into probs below </br></br>\n",
    "<img src=\"probrow.png\" alt=\"Example Image\" width=\"300\" >\n",
    "</br> \n",
    "As you can see the probability distribution for each of the X Inputs is one\n",
    "\n",
    "Logits have the shape [x, 100] @ [100, 27] -> [x, 27], where x is every encoded example as a row and 27 is the prob distribution for each character which sums up to one in every row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br></br>\n",
    "Now lets us look at the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6607e-10, 2.7081e-05, 9.9928e-01, 4.7430e-08, 2.3529e-03, 1.0369e-11,\n",
      "        1.0618e-06, 5.1761e-13, 7.8575e-04, 3.6077e-08, 3.4364e-14, 1.1078e-07,\n",
      "        1.3826e-15, 2.6756e-09, 4.8361e-14, 2.7973e-09, 9.4927e-11, 1.1038e-12,\n",
      "        5.7218e-11, 5.3980e-12, 1.8350e-10, 9.6790e-05, 1.5418e-07, 4.4385e-08,\n",
      "        1.4960e-07, 9.6693e-14, 5.3134e-11, 1.3334e-17, 4.0008e-11, 4.7207e-04,\n",
      "        1.4870e-12, 2.6391e-09])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(20.3157)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enumerator = torch.arange(prob.size(dim = 0))\n",
    "print(prob[enumerator, Y])\n",
    "nll = -prob[enumerator, Y].log().mean() #We put all values from the table below and log them, then we take an average and then we take it by -1 to get a positive number\n",
    "nll # <- Negative Log likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the loss in a much easier way with a built in PyTorch function. Use in practice the expression below for better efficiency. Also backwardpass is much easier\n",
    "Additionally there is one more problem. Look at the image:</br>\n",
    "<img src=\"exp problem.png\" alt=\"Example Image\" width=\"300\" > </br>\n",
    "when some logits get extreme positve values we run out of range (inf) and get a prob nan(Not a number), we can avoid it with the built in function.\n",
    "BUT how does PyTorch make it work? It turns out if you subtract a constant from all logits then we dont affect the prob distribution, so PyTorch looks for the biggest logit and substracts its value from all the logits so when end up with negative logits and 0. Now we can calculate the probs without the (inf) problem and still get the correct result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.3157)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it mean? We print for every row of prob the current probability we give to the actual correct next character (Y if you remember are our labels)\n",
    "Then as you might recall we calculate the negative log likelihood, which we will try to minimize, for our network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = [C, W1, b1, W2, b2]\n",
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "we now rewrite some bits to bring it all together and create the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.315717697143555\n",
      "15.561311721801758\n",
      "12.575206756591797\n",
      "10.628411293029785\n",
      "9.204436302185059\n",
      "8.025666236877441\n",
      "7.002436637878418\n",
      "6.04934024810791\n",
      "5.244919300079346\n",
      "4.538655757904053\n",
      "3.9428608417510986\n",
      "3.4904258251190186\n",
      "3.166780471801758\n",
      "2.911238431930542\n",
      "2.6955888271331787\n",
      "2.50197696685791\n",
      "2.320918560028076\n",
      "2.149221420288086\n",
      "1.986756682395935\n",
      "1.8347790241241455\n",
      "1.694566011428833\n",
      "1.5664585828781128\n",
      "1.4500885009765625\n",
      "1.3449156284332275\n",
      "1.2502349615097046\n",
      "1.1649971008300781\n",
      "1.0879219770431519\n",
      "1.01785409450531\n",
      "0.9539304375648499\n",
      "0.8955068588256836\n",
      "0.8420462608337402\n",
      "0.7930740118026733\n",
      "0.7481948137283325\n",
      "0.7071291208267212\n",
      "0.6697683930397034\n",
      "0.6362210512161255\n",
      "0.6067798137664795\n",
      "0.5817209482192993\n",
      "0.5609772205352783\n",
      "0.543985903263092\n",
      "0.5299080610275269\n",
      "0.5179624557495117\n",
      "0.5075786709785461\n",
      "0.4983762502670288\n",
      "0.49010464549064636\n",
      "0.4825904965400696\n",
      "0.47570833563804626\n",
      "0.46936309337615967\n",
      "0.4634808897972107\n",
      "0.458001971244812\n",
      "0.4528774619102478\n",
      "0.4480670690536499\n",
      "0.4435363709926605\n",
      "0.439256489276886\n",
      "0.4352024793624878\n",
      "0.4313526153564453\n",
      "0.4276886582374573\n",
      "0.42419418692588806\n",
      "0.42085498571395874\n",
      "0.4176579415798187\n",
      "0.41459253430366516\n",
      "0.4116484820842743\n",
      "0.40881678462028503\n",
      "0.4060899615287781\n",
      "0.403460294008255\n",
      "0.40092161297798157\n",
      "0.39846837520599365\n",
      "0.3960946500301361\n",
      "0.3937961459159851\n",
      "0.3915683627128601\n",
      "0.38940709829330444\n",
      "0.38730913400650024\n",
      "0.38527053594589233\n",
      "0.3832886517047882\n",
      "0.38136035203933716\n",
      "0.37948328256607056\n",
      "0.3776547908782959\n",
      "0.37587276101112366\n",
      "0.37413492798805237\n",
      "0.3724393844604492\n",
      "0.3707845211029053\n",
      "0.36916840076446533\n",
      "0.36758947372436523\n",
      "0.3660464286804199\n",
      "0.36453765630722046\n",
      "0.3630618751049042\n",
      "0.3616179823875427\n",
      "0.3602047860622406\n",
      "0.35882115364074707\n",
      "0.3574662208557129\n",
      "0.3561386466026306\n",
      "0.3548378646373749\n",
      "0.35356295108795166\n",
      "0.3523128628730774\n",
      "0.35108721256256104\n",
      "0.34988486766815186\n",
      "0.3487052917480469\n",
      "0.3475477695465088\n",
      "0.346411794424057\n",
      "0.34529662132263184\n"
     ]
    }
   ],
   "source": [
    "for _ in range (100):\n",
    "    #forward pass\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) \n",
    "    logits = h @ W2 + b2 \n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(loss.item())\n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    #update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting:\n",
    "At first we only worked with the first 5 words, so our Model with over 3000 Params overfitted the data extremly, but nevertheless we didnt get loss = 0. Why? It's because already in the data set with have ambiguities like ... -> e and ... -> o </br>\n",
    "This means we can not possibly fit our current model perfectly to the data already. \n",
    "### Now lets look at training the entire data set: \n",
    "Yet again we copy the code for better visibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset but this time with all words\n",
    "\n",
    "block_size = 3 #Number of characters used to predict the next one \n",
    "X, Y = [], [] #X are the inputs, Y are the labels\n",
    "for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + \".\":\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "#Init the embedings C, the params W1, b1, W2, p2\n",
    "C = torch.randn((27, 2)) \n",
    "W1 = torch.randn((6,100))\n",
    "b1 = torch.randn(100) #Every neuron also gets a random bias \n",
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "for p in parameters: \n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we encounter a performance issue, as the training takes really long... The solutions are Minibatches! We calculate the gradient based on some randomly choosen samples (batches). This leads to 2 things:\n",
    "    - Our gradient is of lower quality\n",
    "    - Our trainigssteps are much faster\n",
    "In reality it is better to have a good estimate of the gradient (\"direction we move towards to\") and make more steps then have a precise value and do fewer steps\n",
    "\n",
    "ix = torch.randint(0, X.shape[0], (32,)):\n",
    "- Generates random 32 integers in a tuple from 0 to the length of X (number of examples)\n",
    "\n",
    "emb = C[X[ix]]:\n",
    "- We create a tuple of our embeded Vectors into the 2D space, but only of those 32 from the minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.695675849914551\n"
     ]
    }
   ],
   "source": [
    "for _ in range (10000):\n",
    "    ix = torch.randint(0, X.shape[0], (32,)) #Generates random 32 integers in a tuple from 0 to the length of X (number of examples)\n",
    "\n",
    "    #forward pass\n",
    "    emb = C[X[ix]]\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) \n",
    "    logits = h @ W2 + b2 \n",
    "    loss = F.cross_entropy(logits, Y[ix])\n",
    "    \n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    #update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "print(loss.item()) #Warning... This loss is calculated for the last minibatch not the entire set. Look below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.464693546295166"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We calculate the loss for the entire set\n",
    "emb = C[X]\n",
    "h = torch.tanh(emb.view(-1,6) @ W1 + b1) \n",
    "logits = h @ W2 + b2 \n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our learning steps are currently 0.1, but it is just random... How to determine a good value?\n",
    "\n",
    "Step 1: \n",
    "- We try a couple of values like 0.0001 0.001 0.1 1 10 etc. and see where our steps are way to big (the loss is just jumping around like a kid with ADHD)\n",
    "Step 2:\n",
    "- We create an exponential distribution of the learning steps where the initial steps are small and later steps are bigger\n",
    "Step 3: \n",
    "- For each iteration apply a new learning rate and track the loss\n",
    "Step 4:\n",
    "- Plot it and choose the minimum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRateExponent = torch.linspace(-3, 0 ,1000)\n",
    "learningRateSteps = 10**learningRateExponent\n",
    "learningRateI = []\n",
    "lossI = []\n",
    "for i in range (1000):\n",
    "    ix = torch.randint(0, X.shape[0], (32,)) #Generates random 32 integers in a tuple from 0 to the length of X (number of examples)\n",
    "\n",
    "    #forward pass\n",
    "    emb = C[X[ix]]\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) \n",
    "    logits = h @ W2 + b2 \n",
    "    loss = F.cross_entropy(logits, Y[ix])\n",
    "    \n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    #update\n",
    "    learningRate = learningRateSteps[i]\n",
    "    for p in parameters:\n",
    "        p.data += -learningRate * p.grad\n",
    "    #Track the learning rates\n",
    "    learningRateI.append(learningRateExponent[i])\n",
    "    lossI.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21a9ec482d0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learningRateI, lossI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out our guess that 10**-1 = 0.1 is a good learning step turned out to be good.\n",
    "\n",
    "In practice we would also make our learning rate decay... As our loss gets smaller and starts to stagnate we decrease it to minimize the risk of overshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data Set and Quailty evalution\n",
    "\n",
    "In practice we split our data to e.g: 80% Training Data, 10% Dev/Validation Data, 10% Test Data\n",
    "- Training Data is used for paramter optimazation\n",
    "- Validation Data is used for hyperparameter optimization (number of parameters, number of hidden layers), we basically try a lot of combination to see which works best in our case\n",
    "- Test is for quality evaluation (WARNING: If you test to often, then your model will more and more learn from your test data, and start overfitting the test!!!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
